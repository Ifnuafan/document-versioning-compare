# src/service/compare_service.py

from pathlib import Path
from typing import Dict, Any, List

from ingestion.pdf_loader_ocr import PDFLoaderWithOCR
from ingestion.paragraph_splitter import ParagraphSplitter
from matching.paragraph_matcher import ParagraphMatcher
from diff.diff_engine import DiffEngine
from report.report_builder import ReportBuilder

from analysis.summary_engine import build_summary_text, estimate_risk_level

from db.session import SessionLocal
from db.ops import (
    get_or_create_document,
    create_document_version,
    create_comparison,
    bulk_insert_changes,
)


def run_compare(
    doc_name: str,
    v1_path: str,
    v2_path: str,
    v1_label: str = "v1",
    v2_label: str = "v2",
) -> Dict[str, Any]:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô core ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ 2 ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô
    ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å:
      - main.py (‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô CLI)
      - API / ‡∏á‡∏≤‡∏ô‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å reuse logic ‡πÄ‡∏î‡∏¥‡∏°

    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô dict ‡∏ó‡∏µ‡πà‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö + path ‡∏Ç‡∏≠‡∏á report
    """

    # ‚úÖ ‡πÄ‡∏ä‡πá‡∏Ñ‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô
    if not Path(v1_path).exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {v1_path}")
    if not Path(v2_path).exists():
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {v2_path}")

    # ‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° component ‡∏´‡∏•‡∏±‡∏Å
    loader = PDFLoaderWithOCR()
    splitter = ParagraphSplitter()
    matcher = ParagraphMatcher(threshold=0.6)
    diff_engine = DiffEngine()
    reporter = ReportBuilder()

    # 1) ‡πÇ‡∏´‡∏•‡∏î + ‡πÅ‡∏¢‡∏Å‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
    print("üì• ‡πÇ‡∏´‡∏•‡∏î + ‡πÅ‡∏¢‡∏Å‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ...")
    pages_v1 = loader.load(v1_path)
    paras_v1 = splitter.split(pages_v1)

    pages_v2 = loader.load(v2_path)
    paras_v2 = splitter.split(pages_v2)

    print(f"- {v1_label}: pages={len(pages_v1)}, paragraphs={len(paras_v1)}")
    print(f"- {v2_label}: pages={len(pages_v2)}, paragraphs={len(paras_v2)}")

    # 2) ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤
    print("üîó ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤ ...")
    matches = matcher.match(paras_v1, paras_v2)

    # 3) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
    print("üßÆ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ...")
    changes = diff_engine.build_changes(matches)
    print(f"- ‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(changes)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # 4) ‡∏™‡∏£‡∏∏‡∏õ + ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á
    summary_text = build_summary_text(changes)
    overall_risk_level = estimate_risk_level(changes)

    print("üìä Risk Level:", overall_risk_level)

    # 5) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    db = SessionLocal()
    try:
        # document ‡∏´‡∏•‡∏±‡∏Å
        doc = get_or_create_document(db, doc_name, category=None)

        # version ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        ver1 = create_document_version(db, doc, v1_label, v1_path)
        ver2 = create_document_version(db, doc, v2_label, v2_path)

        # comparison run
        comp = create_comparison(db, doc, ver1, ver2, overall_risk_level, summary_text)

        # map Change objects ‚Üí dicts ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö bulk insert
        change_dicts: List[dict] = []
        for c in changes:
            change_dicts.append(
                {
                    "change_type": c.change_type,
                    "section_label": c.section_label,
                    "old_text": c.old_text,
                    "new_text": c.new_text,
                    "risk_level": None,
                    "ai_comment": None,
                }
            )

        bulk_insert_changes(db, comp, change_dicts)
        db.commit()
        run_id = comp.id
    finally:
        db.close()

    # 6) ‡∏™‡∏£‡πâ‡∏≤‡∏á report (JSON + HTML)
    print("üìù ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô ...")
    json_path = reporter.save_json(
        doc_name=doc_name,
        v1_label=v1_label,
        v2_label=v2_label,
        changes=changes,
        summary_text=summary_text,
        overall_risk_level=overall_risk_level,
    )
    html_path = reporter.save_html(
        doc_name=doc_name,
        v1_label=v1_label,
        v2_label=v2_label,
        changes=changes,
        summary_text=summary_text,
        overall_risk_level=overall_risk_level,
    )

    print("‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    print(f"- JSON report: {json_path}")
    print(f"- HTML report: {html_path}")
    print("‡πÄ‡∏õ‡∏¥‡∏î HTML ‡πÉ‡∏ô browser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")

    # ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ caller ‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
    return {
        "doc_name": doc_name,
        "v1_label": v1_label,
        "v2_label": v2_label,
        "pages_v1": len(pages_v1),
        "pages_v2": len(pages_v2),
        "paragraphs_v1": len(paras_v1),
        "paragraphs_v2": len(paras_v2),
        "changes_count": len(changes),
        "risk_level": overall_risk_level,
        "summary_text": summary_text,
        "json_report_path": str(json_path),
        "html_report_path": str(html_path),
        "run_id": run_id,
    }
